# -*- coding: utf-8 -*-
"""
This module is designed to run PELE energy calculations from clustered results of a 
previous PELE induced fit simulation and apply the correction to the results.
"""

__author__ = "Ignasi Puch-Giner"
__maintainer__ = "Ignasi Puch-Giner"
__email__ = "ignasi.puchginer@bsc.es"

import sys
import os
import pathlib
import argparse
import shutil
from distutils.dir_util import copy_tree
import numpy as np
from collections import Counter


def parse_args(args):
    """
    Function
    ----------
    It parses the command-line arguments.
    Parameters

    Parameters
    ----------
    - args : list[str]
        List of command-line arguments to parse

    Returns
    ----------
    - parsed_args : argparse.Namespace
        It contains the command-line arguments that are supplied by the user
    """

    parser = argparse.ArgumentParser()

    parser.add_argument("-d", "--directory", type=str, dest="input_folder",
                        default='LIG_Pele', help="Name of the directory where the simulation\
        is located.")
    parser.add_argument("-cl", "--clusters_folder", type=str, dest="clusters_folder",
                        default='results', help="Name of the directory containing the folder: clusters.")
    parser.add_argument("-co", "--conf_file_name", type=str, dest="conf_file_name",
                        default='pele', help="Name of the .conf file used for the simulation.")
    parser.add_argument("-rn", "--report_name", type=str, dest="report_name",
                        default='report', help="Name of the report files used for the simulation.")
    parser.add_argument("-r", "--residue_name", type=str, dest="residue_name",
                        default='LIG', help="Ligand's residue name.")
    parser.add_argument("-df", "--data_filter", type=str, dest="data_filter",
                        default='clusters', help="Filter you want to apply to the data. 1) clusters: Only \
        keeps the snaphots that belong to one of the clusters. 2) none: Keeps all the \
        snapshots no matter the cluster they belong to.")
    parser.add_argument("-a", "--action", type=str, dest="action",
                        default='generate', help="Command to let know the script the action you want: (1) generate,\
        (2) analyze or (3) correct.")

    parsed_args = parser.parse_args(args)

    return parsed_args


def linen_results(input_folder,
                  residue_name,
                  clusters_folder,
                  conf_file_name,
                  data_filter):
    """
    Function
    ----------
    It prepares a /simulation folder to perform a PELE energy calculation 
    of all the clustered positions of a previous induced fit PELE simulation.

    Parameters
    ----------
    - input_folder : str
        The path to the directory created by the induced fit simulation.
    - residue_name : str
        Residue name of the ligand in the pdb of each cluster.
    - clusters_folder : str
        Name of the directory where the directory clusters is located (results/analysis).
    - conf_file_name: str
        Name of the .conf file used to run pele (not adaptive.conf).
    - data_filter : str
        Name of the filtering method you want to apply. Only two methods accepted: 1) clusters or 2) none.

    """

    def path_definer(input_folder,
                     clusters_folder):
        """
        Function
        ----------
        Defines all the paths that are going to be used

        Parameters
        ----------
        - input_folder : str
            The path to the directory created by the induced fit simulation.
        - clusters_folder : str
            Name of the directory where the directory clusters is located (results/analysis).

        Returns
        ----------
        - path_previous_simulation: str
            The path to the directory generated by the simulation we want to analyze the clusters
            from.
        - path_clusters : str
            The path to the directory containing the pdbs of the representative poses for each
            cluster.
        - path_energies_input : str 
            The path to the generated directory containing the input proportioned.
        - path_energies_simulation : str
            The path to the generated directory containing all the necessary files to perform the
            PELE energy calculation.
        """

        path = str(pathlib.Path().absolute())
        path_previous_simulation = os.path.join(path, input_folder)
        path_results = os.path.join(path_previous_simulation, clusters_folder)
        path_clusters = os.path.join(path_results, 'clusters')

        if os.path.isdir(path_previous_simulation) == False:
            raise Exception('PathError: There is no folder with this name: ' +
                            path_previous_simulation + '. Please check the path and the folder name.')

        path_energies = os.path.join(path, residue_name + '_linen_a')
        path_energies_input = os.path.join(path_energies, 'input')
        path_energies_simulation = os.path.join(path_energies, 'simulation')

        if os.path.exists(path_energies) == False:
            os.mkdir(path_energies)

        if os.path.exists(path_energies_input) == False:
            os.mkdir(path_energies_input)

        if os.path.exists(path_energies_simulation) == False:
            os.mkdir(path_energies_simulation)

        return path_previous_simulation, path_clusters,\
            path_energies_input, path_energies_simulation

    def conf_information_extraction(path_previous_simulation,
                                    conf_file_name):
        """
        Function
        ----------
        Extracts force field and solvent model from the .conf file.

        Parameters
        ----------
        - path_previous_simulation : str
            Path to the directory where the induced fit simulation is located.
        - conf_file_name : str
            Name of the .conf file used in the induced fit simulation.

        Returns
        ----------
        - forcefield : str
            Force field model used in the induced fit simulation
        - solvent : str
            Solvent model used in the induced fit simulation.
        """

        files = files = os.listdir(path_previous_simulation)

        #
        print(' -   Extracting information from ' + conf_file_name + '.conf.')
        #

        cont_conf = 0

        for document in files:

            if conf_file_name + '.conf' in document:

                cont_conf = 1

                with open(os.path.join(path_previous_simulation, document)) as filein:

                    for line in filein:

                        if "ForceField" in line:

                            line = line.split(':')
                            line = line[1].split('     ')
                            line = line[0].split('"')
                            forcefield = line[1]

                        elif "VDGBNP" in line:

                            solvent = 'VDGBNP'

                        elif "OBC" in line:

                            solvent = 'OBC'

        if cont_conf == 0:

            print('     -   No .conf file was found.')
            forcefield = 'OPLS2005'
            solvent = 'VDGBNP'

        #
        print('     -   Forcefield used:', forcefield + '.')
        print('     -   Solvent model used:', solvent + '.')
        #

        return forcefield, solvent

    def write_files(path,
                    label,
                    forcefield,
                    solvent,
                    run_file_labels):
        """
        Function
        ----------
        Writes all the necessary files to run an energy calculation.

        Parameters
        ----------
        - path : str
            Path to the directory where the .conf is located
        - label : str
            Identifying label of the clustger to be analyzed.
        - forcefield : str
            Force field to be used in the upcoming simulation.
        - solvent : str
            Solvent model to be used in the upcoming simulation.
        """

        with open(os.path.join(path, 'energy' + label + '.conf'), 'w') as fileout:

            fileout.writelines(
                '{\n'
                '   "licenseDirectoryPath" : "/gpfs/projects/bsc72/PELE++/license",'
                '\n'
                '   "Initialization" : {\n'
                '      "Complex" : {\n'
                '         "files" : [\n'
                '            {\n'
                '               "path": "' + path + '/cluster_' + label + '.pdb"\n'
                '            }\n'
                '         ]\n'
                '      },\n'
                '      "ForceField" : "' + forcefield + '",\n'
                '      "Solvent" : {\n'
                '         "ionicStrength" : 0.250,\n'
                '         "solventType" : "' + solvent + '",\n'
                '         "useDebyeLength" : true\n'
                '      }\n'
                '   },\n'
                '   "commands" : [\n'
                '             {\n'
                '                 "commandType": "minimization",\n'
                '                 "Minimizer":\n'
                '                 {\n'
                '                     "algorithm": "TruncatedNewton",\n'
                '                     "parameters":\n'
                '                     {\n'
                '                         "MinimumRMS": 0.05\n'
                '                     }\n'
                '                 }\n'
                '             },\n'
                '             {\n'
                '                 "commandType":"energyComputation"\n'
                '             }\n'
                '         ]\n'
                '}\n'
            )

        with open(os.path.join(path_energies_simulation, 'run'), 'w') as fileout:

            fileout.writelines(
                '#!/bin/bash\n'
                '#SBATCH -J PELEne\n'
                '#SBATCH --output=PELEne.out\n'
                '#SBATCH --error=PELEne.err\n'
                '#SBATCH --qos=debug\n'
                '#SBATCH --time=00:30:00\n'
                '\n'
                'module purge\n'
                'module load intel mkl impi gcc\n'
                'module load impi\n'
                'module load boost/1.64.0\n'
                '\n'
                'list="' + run_file_labels + '"\n'
                '\n'
                'for i in $list\n'
                'do\n'
                '\n'
                '    echo " --------------------------------------------------------------------"\n'
                '    echo "|                         _ CLUSTER _ $i _                           |"\n'
                '    echo " --------------------------------------------------------------------"\n'
                '    /gpfs/projects/bsc72/PELE++/mniv/V1.7.1/bin/PELE-1.7.1_serial ' +
                path_energies_simulation + '/cluster_${i}/energy${i}.conf\n'
                '    echo " "\n'
                '    echo "**********************************************************************"\n'
                '    echo "**********************************************************************"\n'
                '    echo " "\n'
                '\n'
                'done\n'
            )

    def cluster_analysis():

        cluster_files = []
        labels = []

        # Storing information and copying files
        if os.path.isdir(path_clusters):

            files = os.listdir(path_clusters)

            for document in files:

                if 'cluster' in document and '.pdb' in document:

                    cluster_files.append(os.path.join(
                        path_energies_simulation, document))
                    labels.append((document.split('cluster_'))
                                  [1].split('.pdb')[0])
                    shutil.copy(os.path.join(path_clusters, document),
                                path_energies_input)

        # List of clusters' letters for the run_file
        run_file_labels = ' '.join(labels)

        #
        print(' -   Number of clusters obtained in the simulation:', len(labels))
        #

        # Removing the protein from the pdbs.
        clusters = os.listdir(path_energies_input)

        for cluster in clusters:

            if cluster.startswith('cluster'):

                with open(os.path.join(path_energies_input, cluster)) as filein:

                    lines = (l for l in filein if residue_name in l)
                    new_path = path_energies_simulation + \
                        '/' + cluster.split('.pdb')[0]
                    path_DataLocal = path_energies_simulation + '/DataLocal'

                    if os.path.exists(new_path) == False:
                        os.mkdir(new_path)

                    if os.path.exists(path_DataLocal) == False:
                        os.mkdir(path_DataLocal)

                    copy_tree(os.path.join(path_previous_simulation,
                                           'DataLocal'), path_DataLocal)

                    with open(os.path.join(new_path, cluster), 'w') as fileout:

                        fileout.writelines(lines)

            else:
                continue

        forcefield, solvent = \
            conf_information_extraction(
                path_previous_simulation, conf_file_name)

        #
        print(' -   Generating control files for the energy calculation.')
        #

        for label in labels:

            new_path = os.path.join(
                path_energies_simulation + '/cluster_' + label)
            write_files(new_path, label, forcefield, solvent, run_file_labels)

        #
        print(' ')
        print('------------------------------ INFO -------------------------------')
        print(' (1) ')
        print(' -   To run the energy calculation for all the clusters:')
        print('     :> cd ' + residue_name + '_linen_a/simulation')
        print('     :> sbatch run')
        print(' -   Results are stored in PELEne.out.')
        print(' (2) ')
        print(' -   To gather the results in a csv file:')
        print(' -   Go to ' + residue_name + '_linen/simulation directory.')
        print('     :> python /path/to/code/linen_res.py -a analyze')
        print(' ')
        print(' ->   ->    For help: python path/to/code/linen_a.py -h    <-  <-')
        print(' ')
        print('-------------------------------------------------------------------')
        #

    def all_analysis():

        path_output = os.path.join(path_previous_simulation, 'output')

    path_previous_simulation, path_clusters,\
        path_energies_input, path_energies_simulation = \
        path_definer(input_folder, clusters_folder)

    print(' ')
    print('*******************************************************************')
    print('*                          peleLInEn                              *')
    print('* --------------------------------------------------------------- *')
    print('*      Ligand\'s internal energy from induced fit results          *')
    print('* --------------------------------------------------------------- *')
    print('*                          Generation                             *')
    print('*******************************************************************')
    print(' ')

    if data_filter == 'None' or data_filter == 'none':

        print('*            Analysing all snapshots in the simulation            *')
        print(' ')
        all_analysis()

    elif data_filter == 'clusters' or data_filter == 'cluster':

        print('*               Analysing clusters of the simulation              *')
        print(' ')
        cluster_analysis()

    else:
        raise Exception('DataFilterError: The data filter method chosen is not valid. \
        Please choose either: (1) clusters, or (2) none.')


def linen_analyze():
    """
    Function
    ----------
    It gathers the results obtained from the PELE calculation. Putting
    them in order in a csv file.
    """

    path = str(pathlib.Path().absolute())

    lineclusters = []
    linenergies = []

    print(' ')
    print('*******************************************************************')
    print('*                          peleLInEn                              *')
    print('* --------------------------------------------------------------- *')
    print('*      Ligand\'s internal energy from induced fit results          *')
    print('* --------------------------------------------------------------- *')
    print('*                           Analysis                              *')
    print('*******************************************************************')
    print(' ')

    with open(os.path.join(path, 'PELEne.out'), 'r') as filein:

        for line in filein:

            if 'CLUSTER' in line:

                line = line.split('_')
                line = line[2].strip()
                lineclusters.append(line)

            if 'ENERGY VACUUM + SGB + CONSTRAINTS + SELF + NON POLAR:' in line:

                line = line.split(
                    'ENERGY VACUUM + SGB + CONSTRAINTS + SELF + NON POLAR:')
                linenergies.append(float(line[1].strip()))

        sorted_clusters = [x for _, x in sorted(
            zip(linenergies, lineclusters))]
        sorted_energies = sorted(linenergies)

    sorted_energies_corrected = np.array(sorted_energies) - min(linenergies)

    with open('energy.csv', 'w') as fileout:
        fileout.writelines(
            'Cluster,Internal energy,Internal energy change\n'
        )

        for i in range(len(lineclusters)):

            fileout.write(str(sorted_clusters[i]) + ','
                          + str(sorted_energies[i]) + ','
                          + str(sorted_energies_corrected[i]) + '\n')

    #
    print(' -   Results have been stored in energy.csv.')
    print(' -   To apply the corrections obtained:')
    print('     :> cd ../.. ')
    print('     :> python path/to/code/linen_res.py -a correct')
    print(' -   If wanted the flag -df can be added to specify filtering')
    print('     method.')
    print(' ')
    print(' ->   ->    For help: python path/to/code/linen_a.py -h    <-  <-')
    print(' ')
    #


def linen_correction(input_folder,
                     residue_name,
                     clusters_folder,
                     report_name,
                     data_filter):
    """
    Function
    ----------
    It applies the corrections calculated once the analyze action has been
    executed. It does that by (1) reading the energy.csv file generated and the 
    data.csv from the initial simulation, (2) generating a copy of the folders 
    and (3) applying the energy corrections calculated.

    Parameters
    ----------
    - input_folder : str
        The path to the directory created by the induced fit simulation.
    - residue_name : str
        Residue name of the ligand in the pdb of each cluster.
    - clusters_folder : str
        Name of the directory where the directory clusters is located (results/analysis).
    - report_name : str
        Name of the report files we want to correct.
    - data_filter: str
        Name of the filtering method you want to apply. Only two methods accepted: 1) clusters or 2) none.
    """

    def path_definer(input_folder,
                     residue_name, clusters_folder):
        """
        Function
        ----------
        Defines all the paths that are going to be used

        Parameters
        ----------
        - input_folder : str
            The path to the directory created by the induced fit simulation.
        - residue_name : str
            Residue name of the ligand in the pdb of each cluster
        - clusters_folder : str
            Name of the directory where the directory clusters is located (results/analysis).

        Returns
        ----------
        - path_previous_simulation: str
            The path to the directory generated by the simulation we want to analyze the clusters
            from.
        - path_results: str 
            The path to the directory generated by the simulation where all the processed data is kept.
        - path_output : str
            The path to the output folder in the initial simulation.
        - path_energies_simulation : str
            The path to the generated directory containing all the necessary files to perform the
            PELE energy calculation.
        - path_energies_output : str
            The path to the generated directory that is going to contain the modified reports from the corrections.
        """

        path = str(pathlib.Path().absolute())
        path_previous_simulation = os.path.join(path, input_folder)
        path_results = os.path.join(path_previous_simulation, clusters_folder)
        path_output = os.path.join(path_previous_simulation, 'output')

        if os.path.isdir(path_previous_simulation) == False:
            raise Exception('PathError: There is no folder with this name: ' +
                            path_previous_simulation + '. Please check the path and the folder name.')

        path_energies = os.path.join(path, residue_name + '_linen')
        path_energies_input = os.path.join(path_energies, 'input')
        path_energies_simulation = os.path.join(path_energies, 'simulation')

        if os.path.exists(path_energies) == False:
            os.mkdir(path_energies)

        if os.path.exists(path_energies_input) == False:
            os.mkdir(path_energies_input)

        if os.path.exists(path_energies_simulation) == False:
            os.mkdir(path_energies_simulation)

        return path_previous_simulation, path_results, path_output,\
            path_energies_input, path_energies_simulation

    # Dictionaries for the clusters
    labelsdict_ltn = {
        'A': '0', 'B': '1', 'C': '2', 'D': '3', 'E': '4', 'F': '5', 'G': '6', 'H': '7', 'I': '8', 'J': '9',
        'K': '10', 'L': '11', 'M': '12', 'N': '13', 'O': '14', 'P': '15', 'Q': '16', 'R': '17', 'S': '18',
        'T': '19', 'U': '20', 'V': '21', 'W': '22', 'X': '23', 'Y': '24', 'Z': '25'
    }

    labelsdict_ntl = {v: k for k, v in labelsdict_ltn.items()}

    # Paths
    path_previous_simulation, path_results, path_output,\
        path_energies_input, path_energies_simulation\
        = path_definer(input_folder, residue_name, clusters_folder)

    #
    print(' ')
    print('*******************************************************************')
    print('*                          peleLInEn                              *')
    print('* --------------------------------------------------------------- *')
    print('*      Ligand\'s internal energy from induced fit results          *')
    print('* --------------------------------------------------------------- *')
    print('*                          Correction                             *')
    print('*******************************************************************')
    print(' ')
    #

    if os.path.isfile(os.path.join(path_results, 'data.csv')):
        shutil.copy(os.path.join(path_results, 'data.csv'),
                    path_energies_input)

    else:
        raise Exception(
            'DataSimulationNotFound: No data.csv file was found in ' + path_results)

    if data_filter == 'none' or data_filter == 'None':

        #
        print(' -   Data filter chosen: ' +
              data_filter + '. Keeping all the data.')
        print('     -   Copying all the reports.')
        #

        cont_reports = 0

        # Copying reports
        if os.path.isdir(path_output):

            files = os.listdir(path_output)

            for folder in files:
                if folder.isnumeric():

                    full_path = os.path.join(path_output, folder)

                files_subdir = os.listdir(full_path)

                for report in files_subdir:
                    if report.startswith(report_name) and report.split(report_name + '_')[1].isnumeric():

                        shutil.copy(os.path.join(full_path, report),
                                    os.path.join(full_path, 'mod_' + report_name + '_' + report.split(report_name + '_')[1]))
                        cont_reports += 1

                    else:
                        continue

                if cont_reports == 0:

                    raise Exception('ReportNameError: No reports beginning with \"' + report_name + '\" were found in '
                                    + full_path + '.')

    elif data_filter == 'cluster' or data_filter == 'clusters':

        #
        print(' -   Data filter chosen: ' + data_filter + '.')
        print('     -   Only keeping snapshots belonging to main clusters.')
        #

    else:

        raise Exception('DataFilterError: The data filter method chosen is not valid. \
        Please choose either: (1) clusters, or (2) none.')

    # Retrieving cluster information
    cont = 0

    labels_letter = []
    labels = []
    clustersdict = {}

    # Opening file with data from PELE energy simulation.
    with open(os.path.join(path_energies_simulation, 'energy.csv')) as filein:

        for line in filein:

            if cont != 0:

                line = line.split(',')
                labels_letter.append(line[0])
                labels.append(labelsdict_ltn[line[0]])
                clustersdict[line[0]] = float(line[1])

            cont += 1

    # Retrieving simulation information
    cont = 0

    step = []
    cluster = []
    report_paths = []
    folders = []

    with open(os.path.join(path_results, 'data.csv')) as filein:

        for line in filein:

            if cont != 0:

                line = line.split(',')
                cluster_label = line[-1].split()[0]

                if any(label == cluster_label for label in labels):

                    path_string = line[-2].split('trajectory_')[0]
                    path_string = path_previous_simulation + \
                        path_string.split(input_folder)[1]

                    whole_path = str(line[-2])
                    report_num = whole_path.split('/')[-1]
                    report_num = report_num.split('.pdb')[0].split('_')[1]

                    step.append(int(line[0]))
                    cluster.append(int(line[-1].split('\n')[0]))
                    report_paths.append(os.path.join(path_string,
                                                     report_name + '_' + str(report_num)))
                    folders.append(
                        path_string[:-1].replace(input_folder, residue_name + '_linen'))

            cont += 1

    folders = sorted(Counter(folders))

    report_paths_dictionary = Counter(report_paths)
    report_paths = sorted(report_paths)

    cont_cluster = 0

    for folder in folders:

        if os.path.exists(folder) == False:
            os.mkdir(folder)

    #
    print(' -   Implementing correction.')
    #

    with open(os.path.join(path_previous_simulation, 'run_analysis'), 'w') as fileout:

        fileout.writelines(
            '#!/bin/bash\n'
            '#SBATCH --job-name=analysis\n'
            '#SBATCH --output=analysis.out\n'
            '#SBATCH --error=analysis.err\n'
            '#SBATCH --ntasks=48\n'
            '#SBATCH --qos=debug\n'
            '#SBATCH --time=00-01:00:00\n'
            '\n'
            'module load ANACONDA/2019.10\n'
            'module load intel mkl impi gcc # 2> /dev/null\n'
            'module load impi\n'
            'module load boost/1.64.0\n'
            '\n'
            'eval "$(conda shell.bash hook)"\n'
            'conda activate /gpfs/projects/bsc72/conda_envs/platform/1.6.0\n'
            '\n'
            'python script.py\n'
        )

    with open(os.path.join(path_previous_simulation, 'script.py'), 'w') as fileout:

        fileout.writelines(
            'from pele_platform.analysis import Analysis\n'
            '\n'
            'analysis = Analysis(resname="' + residue_name +
            '", chain="L", simulation_output="output", report="' +
            'mod_' + report_name + '", cpus=48)\n'
            'analysis.generate(path="analysis", clustering_type="meanshift")\n'
        )

    # Main loop
    for key in report_paths_dictionary:

        path_string_out = key.replace(report_name, 'mod_' + report_name)

        steps_in_report = step[:report_paths_dictionary[key]]

        cont = 0

        with open(path_string_out, 'w') as fileout:

            with open(key) as filein:

                for line in filein:

                    if cont != 0:

                        line = line.split()

                        if int(line[1]) == steps_in_report[0] and len(steps_in_report) > 1:

                            cluster_number = str(cluster[cont_cluster])
                            cluster_letter = labelsdict_ntl[cluster_number]
                            cluster_energy = clustersdict[cluster_letter]
                            line[4] = str(float(line[4]) - cluster_energy)

                            fileout.write("     ".join(line) + '\n')

                            steps_in_report = steps_in_report[1:]
                            cont_cluster += 1

                        elif int(line[1]) == steps_in_report[0] and len(steps_in_report) == 1:

                            cluster_number = str(cluster[cont_cluster])
                            cluster_letter = labelsdict_ntl[cluster_number]
                            cluster_energy = clustersdict[cluster_letter]

                            line[4] = str(float(line[4]) - cluster_energy)

                            fileout.write("     ".join(line) + '\n')

                            cont_cluster += 1

                        else:

                            if data_filter == 'none' or data_filter == 'None':

                                fileout.write("     ".join(line) + '\n')

                            elif data_filter == 'clusters' or data_filter == 'cluster':
                                continue

                    else:

                        fileout.write(line)

                    cont += 1

            step = step[report_paths_dictionary[key]:]

    #
    print(' -   run_analysis and script.py files have been generated.')
    print(' -   To perform a new analysis:')
    print('     :> cd ' + input_folder)
    print('     :> sbatch run_analysis')
    print(' -   The new plots and files will be in /analysis.')
    print(' ')
    print(' ->   ->    For help: python path/to/code/linen_a.py -h    <-  <-')
    print(' ')
    #


def main(args):
    """
    Function
    ----------
    It reads the command-line arguments and runs linen_results.

    Parameters
    ----------
    - args : argparse.Namespace
        It contains the command-line arguments that are supplied by the user
    """

    if args.action == 'generate':

        linen_results(input_folder=args.input_folder,
                      residue_name=args.residue_name,
                      clusters_folder=args.clusters_folder,
                      conf_file_name=args.conf_file_name,
                      data_filter=args.data_filter)

    elif args.action == 'analyze':

        linen_analyze()

    elif args.action == 'correct':

        linen_correction(input_folder=args.input_folder,
                         residue_name=args.residue_name,
                         clusters_folder=args.clusters_folder,
                         report_name=args.report_name,
                         data_filter=args.data_filter)

    else:
        raise('ActionError: The actions the script can perform are either: generate, analyze or correct.\
        Check the spelling and the capital letters. ')


if __name__ == '__main__':

    args = parse_args(sys.argv[1:])
    main(args)
